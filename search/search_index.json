{"config":{"lang":["en"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"punkst","text":"<p>punkst collects tools for analyzing high resolution spatial transcriptomics data.</p>"},{"location":"#pixel-level-factor-analysis","title":"Pixel level factor analysis","text":"<p>The punkst toolkit provides a pipeline for efficient pixel level factor analysis, which achieves the same result as FICTURE (2024) with improved efficiency.</p>"},{"location":"#workflow-overview","title":"Workflow Overview","text":"<p>Check the quick start page for help on generating the full workflow using Makefile or running each command step by step.</p> <ol> <li>pts2tiles: Group pixels to tiles for faster processing</li> <li>tiles2hex: Group pixels into non-overlapping hexagons</li> <li>lda4hex: Run factorization on the hexagon data</li> <li>pixel-decode: Annotate each pixel with the top factors and their probabilities</li> <li>Visualization: Create a high resolution visualization of the results</li> </ol> <p>All analyses are parallelized and some steps need to write temporary files. Choose the number of threads and the temporary directory (must be empty or can be created) to match your system capabilities.</p> <p>Check the Modules section for detailed documentation of each command.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"examples/basic/","title":"Pixel Level Factor Analysis Example","text":"<p>This example demonstrates how to perform pixel level factor analysis with punkst, achieving similar results to FICTURE (2024) with improved efficiency.</p>"},{"location":"examples/basic/#use-example-makefile","title":"Use example Makefile","text":"<p>We provide a template Makefile and config file in <code>./docs/examples/basic</code> to generate the full workflow of FICTURE.</p> <p>You can copy <code>./docs/examples/basic/config.json</code> to your own directory and modify the data path and parameters, then use <code>ext/py/generate_workflow.py</code> to generate a data-specific Makefile for your task.</p> <p>The python script also generates a bash script that can be submitted as a slurm job. If you are not using slurm just ignore the params in the \"job  section of the config and ignore the generated bash script.</p> <pre><code># set repopath to the path of the punkst repo\npython ${repopath}/ext/py/generate_workflow.py -c config.json -o run.sh -m Makefile -t ${repopath}/docs/examples/basic/Makefile\n</code></pre> <p>You can check the generated workflow before execution by <pre><code>make -f Makefile --dry-run\n</code></pre></p>"},{"location":"examples/basic/#step-by-step","title":"Step by step","text":""},{"location":"examples/basic/#setup","title":"Setup","text":"<p>First, set up the environment variables:</p> <pre><code>threads=4           # Number of threads for parallel processing\ntmpdir=./tmp        # Directory for temporary files (must be empty or creatable)\npath=./your_data    # Path to your data directory\n</code></pre>"},{"location":"examples/basic/#input-format","title":"Input Format","text":"<p>The input should be a TSV file with X coordinate, Y coordinate, feature, and count columns.</p>"},{"location":"examples/basic/#step-1-group-pixels-to-tiles","title":"Step 1: Group pixels to tiles","text":"<p>Group pixels into non-overlapping square tiles for faster processing:</p> <pre><code>punkst pts2tiles --in-tsv ${path}/transcripts.tsv --icol-x 0 --icol-y 1 --skip 0 \\\n  --temp-dir ${tmpdir} --tile-size 50000 --tile-buffer 1000 --threads ${threads} \\\n  --out-prefix ${path}/transcripts.tiled\n</code></pre> <p>Key parameters: - <code>--icol-x</code>, <code>--icol-y</code>: Column indices for X and Y coordinates (0-based) - <code>--tile-size</code>: Size (side length) of the square tiles</p> <p>Detailed documentation for pts2tiles</p>"},{"location":"examples/basic/#step-2-create-hexagonal-units","title":"Step 2: Create hexagonal units","text":"<p>Group pixels into non-overlapping hexagons:</p> <pre><code>punkst tiles2hex --in-tsv ${path}/transcripts.tiled.tsv --in-index ${path}/transcripts.tiled.index \\\n  --feature-dict ${path}/features.txt --icol-x 0 --icol-y 1 --icol-feature 2 --icol-int 3 \\\n  --min-count 20 --hex-size 1039 --out ${path}/hex.txt --temp-dir ${tmpdir} --threads ${threads}\n</code></pre> <p>Key parameters: - <code>--icol-feature</code>, <code>--icol-int</code>: Column indices for feature and count(s) - <code>--hex-size</code>: Side length of the hexagons - <code>--min-count</code>: Minimum count for a hexagon to be included</p> <p>Shuffle the output for better training: <pre><code>sort -k1,1 --parallel ${threads} -S 1G ${path}/hex.txt &gt; ${path}/hex.randomized.txt\n</code></pre></p> <p>Detailed documentation for tiles2hex</p>"},{"location":"examples/basic/#step-3-run-lda-on-hexagon-data","title":"Step 3: Run LDA on hexagon data","text":"<p>Perform Latent Dirichlet Allocation on the hexagon data:</p> <pre><code>punkst lda4hex --in-data ${path}/hex.randomized.txt --in-meta ${path}/hex.json \\\n  --n-topics 12 --out-prefix ${path}/hex.lda --transform --min-count-train 50 \\\n  --minibatch-size 512 --threads ${threads} --seed 1 --n-epochs 2\n</code></pre> <p>Key parameters: - <code>--n-topics</code>: Number of topics (factors) to learn - <code>--transform</code>: Generate transform results after model fitting - <code>--min-count-train</code>: Minimum count for a hexagon to be included in training</p> <p>Detailed documentation for lda4hex</p>"},{"location":"examples/basic/#step-4-decode-pixels-with-the-model","title":"Step 4: Decode pixels with the model","text":"<p>Annotate each pixel with top factors and their probabilities:</p> <pre><code>punkst pixel-decode --model ${path}/hex.lda.model.tsv --in-tsv ${path}/transcripts.tiled.tsv \\\n  --in-index ${path}/transcripts.tiled.index --temp-dir ${tmpdir} --out ${path}/pixel.decode.tsv \\\n  --icol-x 0 --icol-y 1 --icol-feature 2 --icol-val 3 --hex-grid-dist 1200 --n-moves 2 \\\n  --min-init-count 20 --pixel-res 50 --threads ${threads} --seed 1 --output-original\n</code></pre> <p>Key parameters: - <code>--model</code>: Model file created by lda4hex - <code>--hex-grid-dist</code>: Center-to-center distance for hexagons - <code>--n-moves</code>: Number of sliding moves to generate anchors - <code>--pixel-res</code>: Resolution for the analysis (in the same unit as coordinates)</p> <p>Detailed documentation for pixel-decode</p>"},{"location":"examples/basic/#step-5-visualize-the-results","title":"Step 5: Visualize the results","text":"<p>Visualize the pixel decoding results:</p> <pre><code>punkst draw-pixel-factors --in-tsv ${path}/pixel.decode.tsv --header-json ${path}/pixel.decode.json \\\n  --in-color ${path}/color.rgb.tsv --out ${path}/pixel.png --scale 100 \\\n  --xmin ${xmin} --xmax ${xmax} --ymin ${ymin} --ymax ${ymax}\n</code></pre> <p>Key parameters: - <code>--in-color</code>: TSV file with RGB colors for each factor - <code>--scale</code>: Scales input coordinates to pixels in the output image - <code>--xmin</code>, <code>--xmax</code>, <code>--ymin</code>, <code>--ymax</code>: Range of coordinates to visualize</p> <p>Generate a color table from LDA results: <pre><code>python punkst/ext/py/color_helper.py --input ${path}/hex.lda.results.tsv --output ${path}/color\n</code></pre></p> <p>Detailed documentation for visualization</p>"},{"location":"modules/","title":"Punkst Modules","text":"<p>Punkst provides several command-line tools for analyzing high resolution spatial (transcriptomics) data. Each module can be used individually or as part of a pipeline.</p>"},{"location":"modules/#available-modules","title":"Available Modules","text":"<ul> <li>pts2tiles: Groups pixels to tiles for faster processing</li> <li>tiles2hex: Groups pixels into non-overlapping hexagons for spot level analysis</li> <li>lda4hex: Runs LDA on the spot level data</li> <li>pixel-decode: Annotates each pixel with the top factors and their probabilities</li> <li>Visualization: Visualizes the pixel level analysis results</li> </ul>"},{"location":"modules/#input-data-format","title":"Input Data Format","text":"<p>The input is a tsv file with the following columns: X, Y, feature, count. Whether the file contains headers or other columns is not relevant, as long as the above four columns are present.</p> <ul> <li> <p>X, Y coordinates can be either integer or float vlaues. (If your coordinates are integers and you would like to keep the original coordinates in the pixel level inference output, set <code>--coords-are-int</code> in <code>punkst pixel-decode</code>). The coordinates can be in arbitrary units, just make sure all scale/size related parameters you later provide should be in the same unit.</p> </li> <li> <p>\"feature\" can be a string or a nonnegative integer corresponding to the index in a feature list.</p> </li> <li> <p>\"count\" is a nonnegative integer. You could apply gene-specific non-negative real valued weights to the count later in analysis.</p> </li> </ul>"},{"location":"modules/lda4hex/","title":"lda4hex","text":"<p><code>lda4hex</code> runs LDA on the hexagon data.</p> <pre><code>punkst lda4hex --in-data ${path}/hex.randomized.txt --in-meta ${path}/hex.json --n-topics 12 --out-prefix ${path}/hex.lda --transform --min-count-train 50 --minibatch-size 512 --threads ${threads} --seed 1 --n-epochs 2 --mean-change-tol 1e-4\n</code></pre> <p>Required:</p> <p><code>--in-data</code> specifies the input data file (created by <code>tiles2hex</code> then shuffled).</p> <p><code>--in-meta</code> specifies the metadata file created by <code>tiles2hex</code>.</p> <p><code>--n-topics</code> specifies the number of topics to learn.</p> <p><code>--out-prefix</code> specifies the prefix for the output files.</p> <p>Optional:</p> <p><code>--threads</code> specifies the number of threads to use.</p> <p><code>--seed</code> specifies the random seed to use.</p> <p><code>--minibatch-size</code> specifies the size of the minibatches to use during training.</p> <p><code>--min-count-train</code> specifies the minimum count for a hexagon to be included in the training set.</p> <p><code>--n-epochs</code> specifies the number of epochs to train for.</p> <p><code>--mean-change-tol</code> specifies the tolerance for convergence in the e-step in terms of the mean absolute change in the topic proportions of a document. The default is <code>0.002</code> divided by the number of topics.</p> <p><code>--feature-names</code> specifies a file with the names of features, one per line, corresponding to the feature indices in the input file. It is used only if the json file provided by <code>--in-meta</code> does not contains a feature dictionary.</p> <p><code>--feature-weights</code> specifies a file to weight each feature. If feature names are provided either in the json file or with <code>--feature-names</code>, the weight file should contain the feature names in the first column and the weights in the second column. Otherwise, the first column should contain the feature indices.</p> <p><code>--default-weight</code> specifies the default weight for features not present in the weights file (only if <code>--feature-weights</code> is specified).</p> <p><code>--transform</code> specifies whether to transform the data after model fitting. If set, an output file <code>prefix.results.tsv</code> will be created.</p>"},{"location":"modules/pixel-decode/","title":"pixel-decode","text":""},{"location":"modules/pixel-decode/#pixel-level-decoding","title":"Pixel level decoding","text":"<p><code>pixel-decode</code> takes a model and the tiled pixel level data to annotate each pixel with the top factors and their probabilities.</p> <pre><code>punkst pixel-decode --model ${path}/hex.lda.model.tsv --in-tsv ${path}/transcripts.tiled.tsv --in-index ${path}/transcripts.tiled.index --temp-dir ${tmpdir} --out ${path}/pixel.decode.tsv --icol-x 0 --icol-y 1 --icol-feature 2 --icol-val 3 --hex-grid-dist 1200 --n-moves 2 --min-init-count 20 --pixel-res 50 --threads ${threads} --seed 1 --output-original\n</code></pre> <p>The pixel level inference result (in this case <code>${path}/pixel.decode.tsv</code>) contains the coordinates and the inferred top factors and their posterior probabilities for each pixel. We also create a pseudobulk file (<code>${path}/pixel.decode.pseudobulk.tsv</code>) where each row is a gene and each column is a factor.</p>"},{"location":"modules/pixel-decode/#required-parameters","title":"Required Parameters","text":"<p><code>--in-tsv</code> specifies the tiled data created by <code>pts2tiles</code>.</p> <p><code>--in-index</code> specifies the index file created by <code>pts2tiles</code>.</p> <p><code>--icol-x</code>, <code>--icol-y</code> specify the columns with X and Y coordinates (0-based).</p> <p><code>--icol-feature</code> specifies the column index for feature (0-based).</p> <p><code>--icol-val</code> specifies the column index for count/value (0-based).</p> <p><code>--model</code> specifies the model file where the first column contains feature names and the subsequent columns contain the parameters for each factor. The format should match that created by <code>lda4hex</code>.</p> <p><code>--out</code> specifies the output file.</p> <p><code>--temp-dir</code> specifies the directory to store temporary files.</p> <p>One of <code>--hex-size</code> or <code>--hex-grid-dist</code>: <code>--hex-size</code> specifies the size (side length) of the hexagons for initializing anchors; <code>--hex-grid-dist</code> specifies center-to-center distance in the axial coordinate system used to place anchors. <code>hex-grid-dist</code> equals <code>hex-size * sqrt(3)</code>.</p> <p>One of <code>--anchor-dist</code> or <code>--n-moves</code>: <code>--anchor-dist</code> specifies the distance between adjacent anchors; <code>--n-moves</code> specifies the number of sliding moves in each axis to generate the anchors. If <code>--n-moves</code> is <code>n</code>, <code>anchor-dist</code> equals <code>hex-grid-dist</code> / <code>n</code>.</p>"},{"location":"modules/pixel-decode/#optional-parameters","title":"Optional Parameters","text":""},{"location":"modules/pixel-decode/#input-parameters","title":"Input Parameters","text":"<p><code>--coords-are-int</code> if set, indicates that the coordinates are integers; otherwise, they are treated as floating point values.</p> <p><code>--feature-is-index</code> if set, the values in <code>--icol-feature</code> are interpreted as feature indices. Otherwise, they are expected to be feature names.</p> <p><code>--feature-weights</code> specifies a file to weight each feature. The first column should contain the feature names, and the second column should contain the weights.</p> <p><code>--default-weight</code> specifies the default weight for features not present in the weights file (only if <code>--feature-weights</code> is specified). Default is 0.</p> <p><code>--anchor</code> specifies a file containing anchor points to use in addition to evenly spaced lattice points.</p>"},{"location":"modules/pixel-decode/#processing-parameters","title":"Processing Parameters","text":"<p><code>--pixel-res</code> resolution for the analysis, in the same unit as the input coordinates. The default is <code>1</code> so each pixel is treated independently. Setting the resolution equivalent to \\(0.5\\sim 1 \\mu m\\) is recommended, but it could be smaller if your data is very dense.</p> <p><code>--radius</code> specifies the radius within which to search for anchors. If not specified, it defaults to <code>anchor-dist * 1.2</code>.</p> <p><code>--min-init-count</code> specifies the minimum total count within the hexagon around an anchor for the anchor to be included. It will filter out regions outside tissues with sparse noise. Default is 10.</p> <p><code>--threads</code> specifies the number of threads to use. Default is 1.</p> <p><code>--seed</code> specifies the random seed to use for reproducibility. If not provided, a random seed will be generated.</p>"},{"location":"modules/pixel-decode/#output-parameters","title":"Output Parameters","text":"<p><code>--output-original</code> if set, the original data including the feature names and counts will be included in the output. If <code>pixel-res</code> is not <code>1</code> and <code>--output-original</code> is not set, the output contains results per collapsed pixel.</p> <p><code>--use-ticket-system</code> if set, the order of pixels in the output file is deterministic so the same between runs (though not the same asthat in the input). This may incurr a small performance penalty.</p> <p><code>--top-k</code> specifies the number of top factors to include in the output. Default is 3.</p> <p><code>--output-coord-digits</code> specifies the number of decimal digits to output for coordinates (only used if input coordinates are float or <code>--output-original</code> is not set). Default is 4.</p> <p><code>--output-prob-digits</code> specifies the number of decimal digits to output for probabilities. Default is 4.</p>"},{"location":"modules/pts2tiles/","title":"pts2tiles","text":""},{"location":"modules/pts2tiles/#group-pixels-to-tiles-for-faster-processing","title":"Group pixels to tiles for faster processing","text":"<p><code>pts2tiles</code> creates a plain tsv file that reorders the lines in the input file so that coordinates are grouped into non-overlapping square tiles. The ordering of lines within a tile is not guaranteed. It also creates an index file storing the offset of each tile to support fast access.</p> <p>Example usage <pre><code>punkst pts2tiles --in-tsv ${path}/transcripts.tsv --icol-x 0 --icol-y 1 --skip 0 --temp-dir ${tmpdir} --tile-size 50000 --tile-buffer 1000 --threads ${threads} --out-prefix ${path}/transcripts.tiled\n</code></pre></p> <p><code>--icol-x</code>, <code>--icol-y</code> specify the columns with X and Y coordinates (0-based).</p> <p><code>--skip</code> specifies the number of lines to skip in the input file (if your input file contains headers, set it to the number of header lines).</p> <p><code>--tile-size</code> specifies the size (side length) of the squared tiles. The unit is the same as the coordinates in the input file.</p> <p><code>--tile-buffer</code> specifies the per-thread per-tile buffer size in terms of the number of lines before writting to disk. This is not terribly crucial, if the number of tiles may be huge and you are using a large number of threads so that the total memory usage is too high, choose a smaller number.</p> <p><code>--temp-dir</code> specifies the directory for temporary files.</p> <p><code>--threads</code> specifies the number of threads to use.</p> <p><code>--out-prefix</code> specifies the prefix for the output files.</p>"},{"location":"modules/tiles2hex/","title":"tiles2hex","text":"<p><code>tiles2hex</code> groups pixels into nonoverlapping hexagons for spot level analysis.</p> <p>The input is the tiled data created by <code>pts2tiles</code>. The output is a plain tab-delimited text file, each line representing one hexagon intended for internal use. It also writes metadata to a json file.</p>"},{"location":"modules/tiles2hex/#basic-usage","title":"Basic Usage","text":"<pre><code>punkst tiles2hex --in-tsv ${path}/transcripts.tiled.tsv --in-index transcripts.tiled.index --feature-dict ${path}/features.txt --icol-x 0 --icol-y 1 --icol-feature 2 --icol-int 3 --min-count 20 --hex-size ${hex_size} --out ${path}/hex.txt --temp-dir ${tmpdir} --threads ${threads}\n</code></pre>"},{"location":"modules/tiles2hex/#required-parameters","title":"Required Parameters","text":"<p><code>--in-tsv</code> specifies the tiled data created by <code>pts2tiles</code>.</p> <p><code>--in-index</code> specifies the index file created by <code>pts2tiles</code>.</p> <p><code>--icol-x</code>, <code>--icol-y</code>, <code>--icol-feature</code> specify the column indices corresponding to X and Y coordinates and feature (0-based).</p> <p><code>--icol-int</code> specifies the column index for count/value (0-based). You can specify multiple count columns with <code>--icol-int</code>, separated by space.</p> <p><code>--hex-size</code> specifies the side length of the hexagons. The unit is the same as the coordinates in the input file.</p> <p><code>--out</code> specifies the output file.</p>"},{"location":"modules/tiles2hex/#optional-parameters","title":"Optional Parameters","text":"<p><code>--feature-dict</code> specifies a file with the names of features, one per line. It is used only if the values in <code>--icol-feature</code> are to be interpreted as feature names not indices. Features not present in the file will be ignored. (If the input file contains feature indices instead of names, all features will be included in the output)</p> <p><code>--min-count</code> specifies the minimum count for a hexagon to be included in the output.</p> <p><code>--temp-dir</code> specifies the directory for temporary files.</p> <p><code>--threads</code> specifies the number of threads to use.</p>"},{"location":"modules/tiles2hex/#output-format","title":"Output Format","text":"<p>The output is a plain tab-delimited text file. It is not a table: each line contains data for one unit and lines have different number of tokens.</p> <p>The first element in each line of the output is a random key, which can be used to shuffle the data before model training (if you use <code>lda4hex</code> you should always do this):</p> <pre><code>sort -k1,1 --parallel ${threads} -S 1G ${path}/hex.txt &gt; ${path}/hex.randomized.txt\n</code></pre> <p>The remaining of each line is structured as follows:</p> <p>In the basic case, the next two integers after the random key are coordinates (horizontal and vertical) in the axial hexagonal coordinate system.</p> <p>The next 2K tokens (K pairs of non-negative integers) are the number of unique features (\\(M_k\\)) and the total count (\\(C_k\\)) for each modality. The number of modalities (K) is the same as the number of column indices specified in <code>--icol-int</code>.</p> <p>Then there are K chunks of feature values, the k-th chunk containing \\(2M_k\\) (or \\(M_k\\) values) of non-negative integers where \\(M_k\\) is what you read from the previous tokens. The first number in each pair is the indices of the feature, the second is the count of that feature in the hexagon. The indices are 0-based and correspond to the order of features in the <code>--feature-dict</code> file. If <code>--feature-dict</code> is not provided (so the input already codes features as indices), the indices are the same as those in the input file.</p>"},{"location":"modules/tiles2hex/#advanced-usage-spatial-stratification-by-anchor-points","title":"Advanced Usage: Spatial Stratification By Anchor Points","text":"<p><code>tiles2hex</code> can also create multiple sets of units that group pixels that are close to user-provided anchor points. This is useful for creating units stratified by known biological structures for downstream clustering or factorization. A tested use case is to provide nuclear centers as anchor points so likely-nuclear and likely-cytoplasmic pixels are grouped separately.</p> <pre><code>punkst tiles2hex --in-tsv ${path}/transcripts.tiled.tsv --in-index transcripts.tiled.index --feature-dict ${path}/features.txt --icol-x 0 --icol-y 1 --icol-feature 2 --icol-int 3 --min-count 20 --hex-size ${hex_size} --anchor-files ${path}/anchors1.txt ${path}/anchors2.txt --radius ${radius1} ${radius2} --out ${path}/hex.txt --temp-dir ${tmpdir} --threads ${threads}\n</code></pre>"},{"location":"modules/tiles2hex/#additional-parameters-for-anchor-based-analysis","title":"Additional Parameters for Anchor-Based Analysis","text":"<p><code>--anchor-files</code> specifies one or more files containing anchor points. Each anchor file should contain coordinates (x, y) separated by space, one anchor point per line. You can provide multiple anchor files to define different sets of anchor points, separated by space.</p> <p><code>--radius</code> specifies the radius around each anchor point within which pixels will be associated with that anchor. The unit is the same as the coordinates in the input file. You must provide one radius value for each anchor file, in the matched order.</p> <p><code>--ignore-background</code> if set, pixels that are not within the radius of any anchor point will be ignored. By default, these background pixels are included as a separate layer.</p>"},{"location":"modules/tiles2hex/#output-format-for-anchor-based-analysis","title":"Output Format for Anchor-Based Analysis","text":"<p>The output format is similar to the basic usage, but each hexagon also includes a non-negative index as the second token, indicating which anchor set it belongs to. The metadata JSON file includes an additional integer field <code>n_layers</code> recording the number of layers, or the number of anchor sets used (plus one if background is included).</p>"},{"location":"modules/visualization/","title":"Visualization","text":""},{"location":"modules/visualization/#draw-pixel-factors","title":"draw-pixel-factors","text":"<p><code>draw-pixel-factors</code> visualizes the results of <code>pixel-decode</code></p> <pre><code>punkst draw-pixel-factors --in-tsv ${path}/pixel.decode.tsv --header-json ${path}/pixel.decode.json --in-color ${path}/color.rgb.tsv --out ${path}/pixel.png --scale 100 --xmin ${xmin} --xmax ${xmax} --ymin ${ymin} --ymax ${ymax}\n</code></pre> <p><code>--in-tsv</code> specifies the input data file created by <code>pixel-decode</code>.</p> <p><code>--header-json</code> specifies the header created by <code>pixel-decode</code>.</p> <p><code>--in-color</code> specifies a tsv file with the colors for each factor. The first three columns will be interpreted as R, G, B values in the range \\(0-255\\). The valid lines will be assigned to factors in the order they appear in this file.</p> <p><code>--xmin</code>, <code>--xmax</code>, <code>--ymin</code>, <code>--ymax</code> specify the range of the coordinates.</p> <p><code>--scale</code> scales input coordinates to pixels in the output image. <code>int((x-xmin)/scale)</code> equals the horizontal pixel coordinate in the image.</p> <p><code>--out</code> specifies the output png file.</p> <p>If your specified <code>--transform</code> in <code>lda4hex</code>, one way to create the color table is to use the helper python script <pre><code>python punkst/ext/py/color_helper.py --input ${path}/prefix.results.tsv --output ${path}/color\n</code></pre></p>"}]}